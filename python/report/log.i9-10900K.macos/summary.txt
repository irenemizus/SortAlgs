C:	1. Recursive algos are linearly more effective than algos with "home-made" linked lists. I blame my code optimizing skills for that.
	2. For all practically sane array sizes (up to 1B items), the complexity grows almost linearly.
	3. Both recursive algos are very close to each other in terms of performance on a data distribution close to the uniform one. 
	4. Linked list-based implementations are close to linearly different from each other on this type of data. Apparently, the MergeSort() function is just little less effective than the QuickSort() one.
	5. With increasing number of items the difference in performance between linked lists-based and recursive algos slowly tends to one. That can be explained by growing impact of the non-linear term in complexity (Q = a * x + d * x * log(x)). 
	Unfortunately, we can not test this on significantly larger arrays due to the physical RAM limit (the program takes about 20 * Length bytes RAM).
	6. The values captured for small array lengths (up to about 5K items) are not representative because of low accuracy of time measurement. 
	7. There is an unexpected leap of measured times (reduction of performance) by 12% for the linked list-based MergeSort algorithm at about 1M items. I can not explain this...
	
	
